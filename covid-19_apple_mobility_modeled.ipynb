{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"covid_19_apple_mobility_modeled\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'nimble-cortex-266516:covid_19_apple_mobility_modeled' successfully created.\n"
     ]
    }
   ],
   "source": [
    "!bq --location=US mk --dataset {dataset_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Interactive Beam requires Python 3.5.3+.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'covid_19_apple_mobility_staging'\n",
      " projectId: 'nimble-cortex-266516'\n",
      " tableId: 'mobility_report'> referenced by query SELECT * FROM covid_19_apple_mobility_staging.mobility_report limit 10\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset nimble-cortex-266516:temp_dataset_c95a81e3d42f423fbb803a8b593b40ea does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table nimble-cortex-266516.covid_19_apple_mobility_modeled.mobility_report_beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'geo_type'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'region'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'transportation_type'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'alternative_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'date'\n",
      " type: 'DATE'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'change_in_baseline_mobility'\n",
      " type: 'FLOAT'>]>. Result: <Table\n",
      " creationTime: 1589147590221\n",
      " etag: 'YiQlYizYREdA6c4yc+Y6Qw=='\n",
      " id: 'nimble-cortex-266516:covid_19_apple_mobility_modeled.mobility_report_beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1589147590255\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'geo_type'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'region'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'transportation_type'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'alternative_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'date'\n",
      " type: 'DATE'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'change_in_baseline_mobility'\n",
      " type: 'FLOAT'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/nimble-cortex-266516/datasets/covid_19_apple_mobility_modeled/tables/mobility_report_beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'covid_19_apple_mobility_modeled'\n",
      " projectId: 'nimble-cortex-266516'\n",
      " tableId: 'mobility_report_beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.11 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run covid_19_apple_mobility_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589147744.141157/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589147744.141157/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmprlgkv7gu', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589147744.141157/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589147744.141157/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589147744.141157/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmprlgkv7gu', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589147744.141157/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589147744.141157/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589147744.141157/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-05-10T21:55:51.520250Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-05-10_14_55_50-308010911197685523'\n",
      " location: 'us-central1'\n",
      " name: 'separatemobility'\n",
      " projectId: 'nimble-cortex-266516'\n",
      " stageStates: []\n",
      " startTime: '2020-05-10T21:55:51.520250Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-05-10_14_55_50-308010911197685523]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-05-10_14_55_50-308010911197685523?project=nimble-cortex-266516\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-05-10_14_55_50-308010911197685523 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:50.479Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-05-10_14_55_50-308010911197685523.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:50.479Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-05-10_14_55_50-308010911197685523. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:53.562Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:54.310Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:54.910Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:54.937Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write separated log/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:54.969Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.093Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.175Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.264Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.490Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.514Z: JOB_MESSAGE_DETAILED: Fusing consumer Separate Element into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.538Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.604Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/WriteBundles/WriteBundles into Separate Element\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.634Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Separate Element\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.661Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/Pair into Write input/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.686Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.713Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/GroupByKey/Reify into Write input/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.741Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/GroupByKey/Write into Write input/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.764Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/GroupByKey/GroupByWindow into Write input/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.788Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/Extract into Write input/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.818Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/Pair into Write separated log/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.844Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/WindowInto(WindowIntoFn) into Write separated log/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.872Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/GroupByKey/Reify into Write separated log/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.896Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/GroupByKey/Write into Write separated log/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.926Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/GroupByKey/GroupByWindow into Write separated log/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.952Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/Extract into Write separated log/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:55.983Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/InitializeWrite into Write input/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.010Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/InitializeWrite into Write separated log/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.039Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.062Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.094Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.116Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.253Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.400Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/DoOnce/Read+Write separated log/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.429Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/DoOnce/Read+Write input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.441Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.456Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.466Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.478Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.518Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.518Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.575Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:55:56.599Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-05-10_14_55_50-308010911197685523 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:56:20.857Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running stage(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:57:47.303Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:57:47.332Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.449Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/DoOnce/Read+Write input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.506Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.534Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.577Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.603Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.628Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.630Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.646Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.680Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.686Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.716Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:14.742Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.512Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/DoOnce/Read+Write separated log/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.565Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.590Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.646Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.675Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.687Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.705Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.718Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.745Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.753Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.771Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.798Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Separate Element+Write input/Write/WriteImpl/WriteBundles/WriteBundles+Write separated log/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input/Write/WriteImpl/Pair+Write input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input/Write/WriteImpl/GroupByKey/Reify+Write input/Write/WriteImpl/GroupByKey/Write+Write separated log/Write/WriteImpl/Pair+Write separated log/Write/WriteImpl/WindowInto(WindowIntoFn)+Write separated log/Write/WriteImpl/GroupByKey/Reify+Write separated log/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:15.826Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:58:16.630Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_13333884937583038900\". You can check its status with the bq tool: \"bq show -j --project_id=nimble-cortex-266516 dataflow_job_13333884937583038900\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:59:52.803Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_13333884937583038900\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T21:59:53.166Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_14535526496582957360\" started. You can check its status with the bq tool: \"bq show -j --project_id=nimble-cortex-266516 dataflow_job_14535526496582957360\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:23.480Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_14535526496582957360\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:23.503Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_14535526496582957360\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:28.645Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_13333884937583039016\". You can check its status with the bq tool: \"bq show -j --project_id=nimble-cortex-266516 dataflow_job_13333884937583039016\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:39.356Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_13333884937583039016\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:39.833Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Separate Element+Write input/Write/WriteImpl/WriteBundles/WriteBundles+Write separated log/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input/Write/WriteImpl/Pair+Write input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input/Write/WriteImpl/GroupByKey/Reify+Write input/Write/WriteImpl/GroupByKey/Write+Write separated log/Write/WriteImpl/Pair+Write separated log/Write/WriteImpl/WindowInto(WindowIntoFn)+Write separated log/Write/WriteImpl/GroupByKey/Reify+Write separated log/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:39.907Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:39.942Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:39.959Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:39.993Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:40.043Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/GroupByKey/Read+Write separated log/Write/WriteImpl/GroupByKey/GroupByWindow+Write separated log/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:40.084Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/GroupByKey/Read+Write input/Write/WriteImpl/GroupByKey/GroupByWindow+Write input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:43.148Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/GroupByKey/Read+Write separated log/Write/WriteImpl/GroupByKey/GroupByWindow+Write separated log/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:43.214Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:43.287Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:43.315Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:43.406Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:43.408Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:43.473Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:43.504Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:43.560Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:44.390Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/GroupByKey/Read+Write input/Write/WriteImpl/GroupByKey/GroupByWindow+Write input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:44.467Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:44.531Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:44.564Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:44.582Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:44.615Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:44.654Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:44.688Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:44.758Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:45.980Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:46.060Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:46.127Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:46.177Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:46.246Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:46.316Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:47.379Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:47.458Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:47.528Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:47.586Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:47.651Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:47.723Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:49.377Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:50.817Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:50.893Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:51.025Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:51.086Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:00:51.115Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:02:57.019Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:02:57.080Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T22:02:57.116Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-05-10_14_55_50-308010911197685523 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run covid_19_apple_mobility_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
