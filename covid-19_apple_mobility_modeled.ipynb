{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"covid_19_apple_mobility_modeled\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'nimble-cortex-266516:covid_19_apple_mobility_modeled' successfully created.\n"
     ]
    }
   ],
   "source": [
    "!bq --location=US mk --dataset {dataset_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'covid_19_apple_mobility_staging'\n",
      " projectId: 'nimble-cortex-266516'\n",
      " tableId: 'mobility_report'> referenced by query SELECT * FROM covid_19_apple_mobility_staging.mobility_report limit 10\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset nimble-cortex-266516:temp_dataset_689cd016ba5240029952b87441e2b00d does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table nimble-cortex-266516.covid_19_apple_mobility_modeled.mobility_report_beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'geo_type'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'region'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'transportation_type'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'alternative_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'date'\n",
      " type: 'DATE'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'change_in_baseline_mobility'\n",
      " type: 'FLOAT'>]>. Result: <Table\n",
      " creationTime: 1589082584549\n",
      " etag: 's4EhjRuk/OSQJoFXQcl+PQ=='\n",
      " id: 'nimble-cortex-266516:covid_19_apple_mobility_modeled.mobility_report_beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1589082584588\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'geo_type'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'region'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'transportation_type'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'alternative_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'date'\n",
      " type: 'DATE'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'change_in_baseline_mobility'\n",
      " type: 'FLOAT'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/nimble-cortex-266516/datasets/covid_19_apple_mobility_modeled/tables/mobility_report_beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'covid_19_apple_mobility_modeled'\n",
      " projectId: 'nimble-cortex-266516'\n",
      " tableId: 'mobility_report_beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run covid_19_apple_mobility_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589082738.734372/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589082738.734372/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmplw7ml4m2', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589082738.734372/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589082738.734372/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589082738.734372/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmplw7ml4m2', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589082738.734372/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589082738.734372/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://covid_19_cs327_extracredit-dataflow/staging/separatemobility.1589082738.734372/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-05-10T03:52:24.190334Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-05-09_20_52_23-4489769194377014713'\n",
      " location: 'us-central1'\n",
      " name: 'separatemobility'\n",
      " projectId: 'nimble-cortex-266516'\n",
      " stageStates: []\n",
      " startTime: '2020-05-10T03:52:24.190334Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-05-09_20_52_23-4489769194377014713]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-05-09_20_52_23-4489769194377014713?project=nimble-cortex-266516\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-05-09_20_52_23-4489769194377014713 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:23.327Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-05-09_20_52_23-4489769194377014713.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:23.327Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-05-09_20_52_23-4489769194377014713. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:26.376Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:27.411Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.015Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.047Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write separated log/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.068Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write input/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.097Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.127Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.251Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.699Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.724Z: JOB_MESSAGE_DETAILED: Fusing consumer Separate Element into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.750Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.781Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/WriteBundles/WriteBundles into Separate Element\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.809Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Separate Element\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.831Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/Pair into Write input/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.856Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/WindowInto(WindowIntoFn) into Write input/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.880Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/GroupByKey/Reify into Write input/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.904Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/GroupByKey/Write into Write input/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.929Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/GroupByKey/GroupByWindow into Write input/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.955Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/Extract into Write input/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:28.983Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/Pair into Write separated log/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.012Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/WindowInto(WindowIntoFn) into Write separated log/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.036Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/GroupByKey/Reify into Write separated log/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.067Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/GroupByKey/Write into Write separated log/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.101Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/GroupByKey/GroupByWindow into Write separated log/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.130Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/Extract into Write separated log/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.151Z: JOB_MESSAGE_DETAILED: Fusing consumer Write input/Write/WriteImpl/InitializeWrite into Write input/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.172Z: JOB_MESSAGE_DETAILED: Fusing consumer Write separated log/Write/WriteImpl/InitializeWrite into Write separated log/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.200Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.227Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.255Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.283Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.429Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-05-09_20_52_23-4489769194377014713 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.622Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/DoOnce/Read+Write separated log/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.649Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/DoOnce/Read+Write input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.661Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.670Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.686Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.691Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.736Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.736Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.794Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:29.815Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:52:53.410Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running stage(s).\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 2/2)\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:11.347Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:11.375Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:38.938Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/DoOnce/Read+Write input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:38.999Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.026Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.082Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.107Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.137Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.139Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.146Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/DoOnce/Read+Write separated log/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.160Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.191Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.193Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.216Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.245Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.273Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.304Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.333Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.364Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.387Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.389Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.418Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.440Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.491Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.507Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.540Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Separate Element+Write input/Write/WriteImpl/WriteBundles/WriteBundles+Write separated log/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input/Write/WriteImpl/Pair+Write input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input/Write/WriteImpl/GroupByKey/Reify+Write input/Write/WriteImpl/GroupByKey/Write+Write separated log/Write/WriteImpl/Pair+Write separated log/Write/WriteImpl/WindowInto(WindowIntoFn)+Write separated log/Write/WriteImpl/GroupByKey/Reify+Write separated log/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:39.569Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:54:41.492Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_4383905175400452431\". You can check its status with the bq tool: \"bq show -j --project_id=nimble-cortex-266516 dataflow_job_4383905175400452431\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:55:52.701Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_4383905175400452431\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:55:53.248Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_5818467002985353765\" started. You can check its status with the bq tool: \"bq show -j --project_id=nimble-cortex-266516 dataflow_job_5818467002985353765\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:23.815Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_5818467002985353765\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:23.844Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_5818467002985353765\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:29.196Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_4383905175400452227\". You can check its status with the bq tool: \"bq show -j --project_id=nimble-cortex-266516 dataflow_job_4383905175400452227\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:39.909Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_4383905175400452227\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:41.049Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Separate Element+Write input/Write/WriteImpl/WriteBundles/WriteBundles+Write separated log/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write input/Write/WriteImpl/Pair+Write input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write input/Write/WriteImpl/GroupByKey/Reify+Write input/Write/WriteImpl/GroupByKey/Write+Write separated log/Write/WriteImpl/Pair+Write separated log/Write/WriteImpl/WindowInto(WindowIntoFn)+Write separated log/Write/WriteImpl/GroupByKey/Reify+Write separated log/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:41.118Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:41.150Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:41.169Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:41.202Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:41.236Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/GroupByKey/Read+Write separated log/Write/WriteImpl/GroupByKey/GroupByWindow+Write separated log/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:41.262Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/GroupByKey/Read+Write input/Write/WriteImpl/GroupByKey/GroupByWindow+Write input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:44.948Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/GroupByKey/Read+Write separated log/Write/WriteImpl/GroupByKey/GroupByWindow+Write separated log/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:45.011Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:45.072Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:45.099Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:45.119Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:45.145Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:45.178Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:45.209Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:45.265Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:47.251Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/GroupByKey/Read+Write input/Write/WriteImpl/GroupByKey/GroupByWindow+Write input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:47.322Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:47.375Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:47.406Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:47.430Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:47.495Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:47.500Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:47.563Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:47.640Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:49.237Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:49.297Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:49.360Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:49.400Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:49.461Z: JOB_MESSAGE_DEBUG: Value \"Write separated log/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:49.524Z: JOB_MESSAGE_BASIC: Executing operation Write separated log/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:50.475Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:50.526Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:50.583Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:50.625Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:50.687Z: JOB_MESSAGE_DEBUG: Value \"Write input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:50.746Z: JOB_MESSAGE_BASIC: Executing operation Write input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:53.617Z: JOB_MESSAGE_BASIC: Finished operation Write separated log/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:53.806Z: JOB_MESSAGE_BASIC: Finished operation Write input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:53.861Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:53.964Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:54.019Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:56:54.043Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:58:50.179Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:58:50.217Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-05-10T03:58:50.247Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-05-09_20_52_23-4489769194377014713 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run covid_19_apple_mobility_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
